{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mS3dthFFKKF0"
   },
   "source": [
    "# PySpark NLP with Spark NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iyayPMT36B36"
   },
   "source": [
    "Set-up for spark nlp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PD_FLtx_ePz_"
   },
   "outputs": [],
   "source": [
    "#!wget http://setup.johnsnowlabs.com/colab.sh -O - | bash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oSZYnvpP6AXy"
   },
   "source": [
    "Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S6CB0pZfeTVV"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00331/sentiment%20labelled%20sentences.zip\n",
    "!unzip 'sentiment labelled sentences'\n",
    "!mkdir data\n",
    "!mv  \"sentiment labelled sentences\"/* data\n",
    "!cp -r data/yelp_labelled.txt ./ \n",
    "!ls\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yU4NEWge5-XB"
   },
   "source": [
    "Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SxPvx7QLfKGG"
   },
   "outputs": [],
   "source": [
    "import sparknlp\n",
    "spark = sparknlp.start()\n",
    "df = spark.read.csv(\"yelp_labelled.txt\",header=False,sep='\\t',inferSchema=True)\n",
    "df = df.withColumnRenamed(\"_c1\", \"label\")\n",
    "df = df.withColumnRenamed(\"_c0\", \"text\")\n",
    "df.show()\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F0X1hTI64jgB"
   },
   "source": [
    "Create and assemble the pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wYmDo1ttfMFt"
   },
   "outputs": [],
   "source": [
    "from sparknlp.annotator import *\n",
    "from sparknlp.common import *\n",
    "from sparknlp.base import *\n",
    "from pyspark.ml.feature import StopWordsRemover, CountVectorizer, StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "#doc assembler\n",
    "assembler = DocumentAssembler().setInputCol('text').setOutputCol('document')\n",
    "#tokenizer\n",
    "tokenizer = Tokenizer().setInputCols([\"document\"]).setOutputCol('tokenized')\n",
    "#normalizer\n",
    "normalizer = Normalizer().setInputCols(['tokenized']).setOutputCol('normalized')\n",
    "#rm stop words\n",
    "cleaner = StopWordsCleaner().setInputCols('normalized').setOutputCol('cleaned').setCaseSensitive(False)\n",
    "#lemmatizer\n",
    "lemmatizer = Stemmer().setInputCols(['cleaned']).setOutputCol('lemmatized')\n",
    "#finisher\n",
    "finisher = Finisher().setInputCols([\"lemmatized\"]).setOutputCols([\"finished\"]).setOutputAsArray(True).setCleanAnnotations(False)\n",
    "#CountVectorizer\n",
    "cv = CountVectorizer(inputCol=\"finished\", outputCol=\"features\")\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    stages=[\n",
    "            assembler,\n",
    "            tokenizer,\n",
    "            normalizer,\n",
    "            cleaner,\n",
    "            lemmatizer,\n",
    "            finisher,\n",
    "            cv\n",
    "    ]\n",
    ")\n",
    "model = pipeline.fit(df)\n",
    "ready = model.transform(df)\n",
    "ready.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oSqYYPOd4hcZ"
   },
   "source": [
    "Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SwQoxFSLjVdU"
   },
   "outputs": [],
   "source": [
    "(train, test) = ready.randomSplit([0.7, 0.3])\n",
    "print(train.count())\n",
    "print(train.show())\n",
    "print(test.count())\n",
    "print(test.show())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HnJIcnFV4dnr"
   },
   "source": [
    "Testing Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NU2cul1nep70"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LinearSVC\n",
    "lsvcModel = LinearSVC().fit(train)\n",
    "predictions = lsvcModel.transform(test)\n",
    "results = predictions.select(\"text\",\"label\",\"prediction\")\n",
    "results.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u_KHiFqCmD14"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix,accuracy_score\n",
    "true = predictions.select(\"label\").toPandas()\n",
    "pred = predictions.select(\"prediction\").toPandas()\n",
    "print(classification_report(true.label, pred.prediction))\n",
    "print(confusion_matrix(true,pred))\n",
    "print(accuracy_score(true.label, pred.prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b7d_hfL46L6Q"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "lrModel = LogisticRegression().fit(train)\n",
    "predictions = lrModel.transform(test)\n",
    "results = predictions.select(\"text\",\"label\",\"prediction\")\n",
    "results.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1tqOkIaK8FL5"
   },
   "outputs": [],
   "source": [
    "true = predictions.select(\"label\").toPandas()\n",
    "pred = predictions.select(\"prediction\").toPandas()\n",
    "print(classification_report(true.label, pred.prediction))\n",
    "print(confusion_matrix(true,pred))\n",
    "print(accuracy_score(true.label, pred.prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p21odPp6O7pv"
   },
   "source": [
    "Note: For random forest classifier, changing the parameters can greatly improve performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6sar2YdUmLv1"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\")\n",
    "rfModel = rf.fit(train)\n",
    "predictions = rfModel.transform(test)\n",
    "results = predictions.select(\"text\",\"label\",\"prediction\")\n",
    "results.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i48-dt7-mkv9"
   },
   "outputs": [],
   "source": [
    "true = predictions.select(\"label\").toPandas()\n",
    "pred = predictions.select(\"prediction\").toPandas()\n",
    "print(classification_report(true.label, pred.prediction))\n",
    "print(confusion_matrix(true,pred))\n",
    "print(accuracy_score(true.label, pred.prediction))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "SparkNLP",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
